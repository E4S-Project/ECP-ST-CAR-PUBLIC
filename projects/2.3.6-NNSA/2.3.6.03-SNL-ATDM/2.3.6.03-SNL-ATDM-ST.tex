\subsubsection{\stid{6.03} Sandia ATDM Software Technologies}

\paragraph{Overview} \leavevmode \\

The Sandia ATDM Software Technologies projects are now aggregated to include Kokkos, Kokkos kernels, VTK-m, and Operating Systems and On-Node Runtime efforts. 

The Kokkos programming model and C++ library enable performance portable on-compute-node parallelism for HPC/exascale C++ applications. Kokkos has been publicly available at \url{http://github.com/kokkos/kokkos} since May 2015 and is being used and evaluated by projects at DOE laboratories, PSAAP-II centers, other universities, and organizations such as DoD laboratories. Kokkos library implementation consists of a portable application programmer interface (API) and architecture specific back-ends, including OpenMP, Intel Xeon Phi, and CUDA on NVIDIA GPU. These back-ends are developed and optimized as new application-requested capabilities are added to Kokkos, back-end programming mechanisms evolve, and architectures change.

Kokkos Kernels implements on-node shared memory computational kernels for linear algebra and graph operations, using the Kokkos shared-memory parallel programming model. Kokkos Kernels forms the building blocks of a parallel linear algebra library like Tpetra in Trilinos that uses MPI and threads for parallelism, or it can be used stand-alone in ECP applications. Kokkos Kernels supports several Kokkos backends to support architectures like Intel CPUs, KNLs and NVIDIA GPUs. The algorithms and the implementations of the performance-critical kernels in Kokkos Kernels are chosen carefully to match the features of the architectures. This allows ECP applications to utilize high performance kernels and transfers the burden to Kokkos Kernels developers to maintain them in future architectures. Kokkos Kernels also has support for calling vendor provided libraries where there are optimized kernels available.

VTK-m is a toolkit of scientific visualization algorithms for emerging processor architectures. VTK-m supports the fine-grained concurrency for data analysis and visualization algorithms required to drive extreme scale computing by providing abstract models for data and execution that can be applied to a variety of algorithms across many different processor architectures.  The ECP/VTK-m project is building up the VTK-m codebase with the necessary visualization algorithm implementations that run across the varied hardware platforms to be leveraged at the exascale. We will be working with other ECP projects, such as ALPINE, to integrate the new VTK-m code into production software to enable visualization on our HPC systems.  For the ASC/ATDM program, the VTK-m project will concentrate on support of ATDM applications and ASC’s Advanced Technology Systems (ATS) as well as the ASTRA prototype system at Sandia.  General information about VTK-m as well as source code can be found at: http://m.vtk.org.

The OS and On-Node Runtime project focuses on the design, implementation, and evaluation of operating system and runtime system (OS/R) interfaces, mechanisms, and policies supporting the efficient execution of application codes on next-generation platforms. Priorities in this area include the development of lightweight tasking techniques that integrate network communication, interfaces between the runtime and OS for management of critical resources (including multi-level memory, non-volatile memory, and network interfaces), portable interfaces for managing power and energy, and resource isolation strategies at the operating system level that maintain scalability and performance while providing a more full-featured set of system services. The OS/R technologies developed by this project will be evaluated in the context of ATDM application codes running at large-scale on ASC platforms. Through close collaboration with vendors and the broader community, the intention is to drive the technologies developed by this project into vendor-supported system software stacks and gain wide adoption throughout the HPC community.

\paragraph{Key  Challenges} \leavevmode \\

\subparagraph{Kokkos:} The many-core revolution in computing is characterized by:
(1) a steady increase in the number of cores within individual computer chips;
(2) a corresponding decrease in the amount of memory per core that must be shared by the cores of a chip, and,
(3), the diversity of computer chip architectures.
This diversity is highly disruptive because each architecture imposes different complex
and sometimes conflicting requirements on software to perform well on an architecture.
Application software development teams are confronted with the dual challenges of:
(1) inventing new parallel algorithms for many-core chips,
(2) learning the different programming mechanisms of each architecture, and
(2), creating and maintaining separate versions of their software specialized for each architecture.
These tasks may involve considerable overhead for organizations in terms of time and cost.
Adapting application software to changing HPC requirements is already becoming a large expense for
HPC users and can be expected to grow as the diversity of HPC architectures continues to rise.
An alternative, however, is creating software that is performance portable across current and future architectures.

\subparagraph{Kokkos Kernels:} There are several challenges associated with the Kokkos Kernels work. Part of the complexity arises because profiling tools are not yet fully mature for advanced architectures and in this context profiling involves the interplay of several factors which require expert judgment to improve performance.  Another challenging aspect is working on milestones that span a variety of projects and code bases. There is a strong dependence on the various application code development teams for our own team's success. In addition, we face a constant tension between the need for production ready tools and components in a realm where the state-of-the-art is still evolving.

\subparagraph{VTK-m:} The scientific visualization research community has been building scalable HPC algorithms for over 15 years, and today there are multiple production tools that provide excellent scalability \cite{ParaView,Catalyst}. That said, there are technology gaps in data analysis and visualization facing ATDM applications as they move to Exascale.  As we approach Exascale, we find that we can rely less on disk storage systems as a holding area for all data between production (by the simulation) and consumption (by the visualization and analysis). To circumvent this limitation, we must integrate our simulation and visualization into the same workflow and provide tools that allows us to run effectively and capture critical information.

\subparagraph{OS \& ONR:} Exascale challenges for system software span the areas of operating systems, networks, and run time systems.  Container technologies are by now ubiquitous in the cloud computing space, but for HPC their immense potential has been limited by concerns about compatibility with security models and overhead costs.  As vendors bring forward new network hardware for exascale, both vendors and application programmers lack insight into how applications actually use networks in practice, especially regarding the characteristics of the messages sent in production codes.  As programming models like OpenMP at the node level and MPI at the inter-node level evolve, the particular needs of DOE applications must be addressed in both the development of standards and evaluation of provided run time system implementations.



\paragraph{Solution Strategy} \leavevmode \\

\subparagraph{Kokkos: } The Kokkos team developed a parallel programming model with flexible enough semantics that it can be mapped on a diverse set of HPC architectures including current multi-core CPUs and massively parallel GPUs.
The programming model is implemented using C++ template abstractions, which allow a compile time translation to the underlying programming mechanism on each platform, using their respective primary tool chains.
Compared to approaches which rely on source-to-source translators or special compilers, this way leverages the investment of vendors in their preferred programming mechanism without introducing additional, hard to maintain, tools in the compilation chain.

\begin{figure}[ht!]
\centering
\includegraphics[width=90mm]{projects/2.3.6-NNSA/2.3.6.03-SNL-ATDM/kokkos-abstractions.jpg}
\caption{Kokkos Execution and Memory Abstractions}
\end{figure}

\subparagraph{Kokkos Kernels:} The Kokkos Kernels team is taking a staged approach to profiling in regards to target architectures and the algorithms involved. We are also coordinating on a regular basis with the other projects that are involved in our work to minimize impediments. In response to the need for production ready tools, we are focusing on a hierarchical approach that involves producing robust, hardened code for core algorithms while simultaneous pursuing research ideas where appropriate. 
 
\subparagraph{VTK-m:} The VTK-m team is addressing its challenges through
development of portable visualization algorithms for VTK-m and leveraging and
expanding the Catalyst~\cite{Catalyst}  \emph{in situ} visualization library to
apply this technology to ATDM applications on ASC platforms.  VTK-m uses the
notion of an abstract device adapter, which allows algorithms written once in
VTK-m to run well on many computing architectures.  The device adapter is
constructed from a small but versatile set of data parallel primitives, which
can be optimized for each platform~\cite{Blelloch1990}.  It has been shown that
this approach not only simplifies parallel implementations, but also allows
them to work well across many platforms~\cite{Lo2012,Larsen2015,Moreland2015}.

\subparagraph{OS \& ONR:} The OS \& ONR team is buying down risk for the use of containers by demonstrating exemplar application containerizations, e.g., for the ATDM SPARC application.  We work with facilities staff to develop and implement strategies to deploy containers on our HPC systems and with dev-ops teams to ease the developer burden for code teams seeking to use containers.  To better understand network resource utilization, we use an MPI simulator that accepts real network traces of application executions as inputs and provides detailed analysis to inform network hardware vendors and application developers alike.  We participate actively in both the OpenMP Language Committee and MPI Forum.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Recent Progress} \leavevmode \\


\subparagraph{Kokkos:}  In FY21, the most significant accomplishment was the Kokkos 3.4 Release, the release that provides comprehensive support for exascale computing.  This includes complete backends for AMD and Intel GPUs.  The Kokkos team also added a Kokkos “Graph API” to help with latency limited execution cases.  The feature allows the creation of a dependency graph object between multiple kernels, which can be repeatedly submitted for execution. Kokkos Graph can leverage the CUDA Graphs API introduced in CUDA 11.  The Kokkos team also continued to provide high-quality support and consultation for ASC applications and libraries.


\subparagraph{Kokkos Kernels:} In FY21, the most significant accomplishment was the Kokkos Kernels 3.4 Release, the release that provides significant kernel support for exascale computing.  This includes math kernel support for AMD and Intel GPUs, leveraging the vendor math libraries where appropriate and providing native Kokkos implementations where necessary.  Several improvements that are needed have also been identified in vendor math libraries.  In addition, there have been several key algorithm improvements for GPU kernels:
\begin{itemize}
\item Developed a portable MIS-2 algorithm using Kokkos, which is 4-15x faster than state-of-the-art for GPUs. The new implementation has been run on NVIDIA/AMD GPUs and ARM/Intel CPUS.  It has been integrated with the new algorithm with MueLu multigrid solver and should improve multigrid coarsening on GPUs.
\item Improved Kokkos Kernels sparse matrix addition for sorted rows on GPU, now ~50\% faster overall than NVIDIA cuSPARSE.
\item Optimized memory access patterns in Kokkos Kernels dense matrix-vector multiplication. In one Sierra-Thermal Fluids problem on ATS-2 system at LLNL.  This sped up the overall radiosity solve by 15\%.
\item Rewrote Kokkos Kernels Symmetric Gauss Seidel to support sparse matrices with dense rows such as those appear in Sierra-Thermal Fluids problems. This impacts the ASC level 2 milestone results for Sierra-TF. The resulting hierarchical parallel algorithm for dense rows results in 6-8x speedup for Sierra-TF use cases. 
\end{itemize}

The Kokkos Kernels team also continued to provide high-quality support and consultation for ASC applications and libraries.
 

\subparagraph{VTK-m:} The VTK-m team made advances in three areas in FY21: support for performance evaluation of VTK-m, improvements to ParaView/Catalyst to enable \emph{in situ} quantitative analysis, and a tighter integration of I/O and visualization capabilities to improve useability of the visualization tools.  Early in FY21, the team created a driver program to exercise Catalyst and VTK-m without a large-scale application.  The driver processes pre-computed data and has been used to evaluate GPU performance of VTK-m through Catalyst on Sandia's Vortex system. Improvements to the Catalyst 5.9.0 API enable the injection of analysis capabilities without the need to recompile--reducing the dev-ops burden.  In addition, Catalyst now has an ``extract data'' capability to support some of the planned quantitative-analysis capabilities in development for FY22.  Finally, the team worked closely with Sandia's production I/O team to better integrate visualization and I/O.  These include improvements to the IOSS-Catalyst interface, an improved CGNS reader, and a new feature to IOSS that specifies a json-format script for embedded analysis. 

\subparagraph{OS \& ONR:} The OS \& ONR team had a number of recent accomplishments. We completed an in-depth performance analysis of a containerized version of the ATDM SPARC application at scale. We also completed an analysis of the impact of application perturbation from container infrastructure. Results show that containers running without contention for CPU resource have little impact on application perturbation; however, using Linux control groups to partition resources between concurrent containers can lead to noise-like events that have the potential to significantly degrade application performance. We also developed and disseminated a Sandia ASC-wide container strategy that details how to integrate several activities supporting and leveraging container technologies. The strategy includes the creation of working groups, integration with existing DevOps activities, and further development efforts surrounding unprivileged container build solutions. We also led the addition of a new chapter to the MPI Standard on partitioned communication operations. This new functionality is aimed at improving the performance of network operations for highly multithreaded applications as well as more efficient methods of supporting communication from accelerators, such as GPUs and SmartNICs.


\paragraph{Next Steps} \leavevmode \\

\subparagraph{Kokkos: } With the comprehensive Kokkos exascale support in place, the focus of FY22 will be in helping the ASC libraries and application teams to obtain good performance on the early access AMD GPU machines in preparation for El Capitan.  Specifically, the team will work with ASC applications and libraries to evaluate and improve performance on AMD GPUs.  One specific effort will be working with the Trilinos Solvers team to improve their performance on AMD GPUs, which should help smooth the way for applications to El Capitan.  The Kokkos team will also develop initial support for the Vanguard II system and identify future API/optimizations for Vanguard II backend.  The Kokkos team will also continue to provide high-quality support and consulatation for ASC applications and libraries.  This will include providing Kokkos training to ASC customers if the available online recorded tutorials are insufficient and providing support via email, Slack, and Github to ASC customers.

\subparagraph{Kokkos Kernels:} With the initial Kokkos Kernels exascale support in place, the focus of FY22 will be in providing complete kernel support (all needed sparse and dense linear algebra kernels, graph kernels) for the HIP backend (and AMD math library) for ASC libraries and application teams to obtain good performance on the early access AMD GPU machines in preparation for El Capitan.  Specifically, the team will work with ASC applications and libraries to evaluate and improve kernel performance on AMD GPUs.  Some specific efforts are:
\begin{itemize}
\item Working with the Trilinos Solvers team to improve their performance of their component kernels on AMD GPUs.  
\item Providing BlockCrs support (SpMV, SpGEMM) and evaluate/optimize performance on CPUs and GPUs.  
\item Providing point ILU + SpTrsv performance improvements and block ILU+SpTrsv performance improvements (for Sierra-Thermal Fluids ASC L2 milestone).  
\item Providing team level batched ODE solvers (for Sierra-Thermal Fluids ASC L2 milestone).  
\item Ensuring performance of BlockDiag and BlockTridiag solvers on AMD architectures for El Cap readiness.
\end{itemize}

The Kokkos Kernels team will continue to engage the vendor community (Vanguard II vendor, NVIDIA, ARM, AMD) to develop and deliver kernels using Kokkos Kernels as reference implementation to better support ASC/ATDM codes and the broader CSE community.  The Kokkos team also will continue to provide high-quality support and consulatation for ASC applications and libraries.  This will include providing support via email, Slack, and Github to ASC customers.

 
\subparagraph{VTK-m:} The ATDM/VTK-m project will focus on two primary goals in FY22: evaluating and improving VTK-m performance on ATS platforms and providing \emph{in situ} quantitative analysis capabilities in support of an ASC/ATDM Level II milestone on embedded capabilities.   Addressing performance, the VTK-m team will work closely with the ECP VTK-m project to develop a performance evaluation suite and evaluate the Kokkos backend on the ASC ATS and/or Vanguard platforms and will deliver a report evaluating accelerated visualization algorithms on different platforms.  Addressing quantitative analysis, the team will work closely with analysts to identify use-cases for Catalyst that include both visualization and quantitative outputs; then it will identify barriers to utility, useability, and adoption of the ParaView Python interface for the identified use cases.  Results will be published in the FY22 ASC milestone report. 

\subparagraph{OS \& ONR:} We plan to characterize how ASC/ATDM workloads use MPI communication in conjunction with GPUs to better understand workload performance and opportunities for optimization. We also plan to execute on the container infrastructure and support strategy developed last year, continuing to partner with vendors, facilities, and application/library developers to leverage container technologies for ASC/ATDM applications. We will also continue to contribute to the OpenMP and MPI standards bodies to shape the direction of the OpenMP and MPI parallel programming models to provided needed capabilities for ASC workloads.
