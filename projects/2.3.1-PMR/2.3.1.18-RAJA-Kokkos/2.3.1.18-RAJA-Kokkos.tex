\subsubsection{\stid{1.18} ISC4MCM (RAJA)} 

\paragraph{Overview.} 
The Integrated Software Components for Managing Computation and Memory 
Interplay at Exascale (ISC4MCM) project is providing software libraries that 
enable application and library developers to meet advanced architecture 
portability challenges. The project goals are to enable writing performance 
portable computational kernels and coordinate complex heterogeneous memory 
resources among components in a large integrated application. These 
libraries enhance developer productivity by insulating them from much of the 
complexity associated with parallel programming model usage and 
system-specific memory concerns.

The software products provided by this project are three complementary and 
interoperable libraries:
\begin{enumerate}
\item {\bf RAJA:} Software abstractions that enable C++ developers to write
  performance portable (i.e., single-source) numerical kernels (loops). 
\item {\bf CHAI:} C++ ``managed array'' abstractions that enable transparent
  and automatic copying of application data to execution memory spaces at run
    time as needed based on RAJA execution contexts.
\item {\bf Umpire:} A portable memory resource management library that provides
  a unified high-level API for resource discovery, memory provisioning,
    allocation, access, operations, and introspection.
\end{enumerate}

Capabilities delivered by these software efforts are needed to manage the
diversity and uncertainty associated with current and future HPC architecture
design and software support. Moving forward, ECP applications and libraries 
need to achieve performance portability: without becoming bound to particular
(potentially-limiting) hardware or software technologies, by insulating 
numerical algorithms from platform-specific data and execution concerns, and 
without major disruption as new machine, programming models, and vendor
software become available.

These libraries in development in this project are currently used in production
ASC applications at Lawrence Livermore National Laboratory (LLNL). They are
also being used or being explored/adopted by several ECP application and
library projects, including: LLNL ATDM application, GEOS (Subsurface), SW4
(EQSIM), MFEM (CEED co-design), and SUNDIALS.

The software projects are highly-leveraged with other efforts. Team members
include: ASC and ATDM application developers, ASD tool developers, university
collaborators, and vendors. This ECP ST project supports outreach to the ECP
community and collaboration with ECP efforts.

\paragraph{Key Challenges.}

The main technical challenge for this project is enabling production
applications to achieve performance portability in an environment of rapidly
changing, disruptive HPC hardware architecture design. Typical large
applications contain $O(10^5) - O(10^6)$ lines of code and $O(10K)$ loop
kernels. The codes must run efficiently on platforms ranging from laptops to
commodity clusters to large HPC platforms. The codes are long-lived and are
used daily for decades, so they must be portable across machine generations.
Also, the codes are under continual development, with a steady stream of new
capabilities added throughout their lifetimes -- continual validation and
verification is essential, which precludes substantial rewrites from scratch.
Lastly, the complex interplay of multiple physics packages and dozens of
libraries makes it so that the data required for the full set of components
needed for a given simulation may not fit into a single system memory space. To
advance scientific computing capabilities, applications must navigate these
constraints while facing substantial hardware architecture disruption along the
road toward Exascale computing platforms. 

While the software provided by this project has a substantial user base at
LLNL, achieving broader adoption in the ECP (projects without LLNL involvement,
in particular) is another challenge. The software efforts are funded almost
entirely by LLNL programs and the majority of their developers work on LLNL
application projects. So resource limitations is a key issue.

\paragraph{Solution Strategy.}

The software libraries in this project focus on encapsulation and 
application-facing APIs to insulate users from the complexity and 
challenges associated with diverse forms of parallelism and heterogeneous 
memory systems. This approach allows users to exploit new capabilities 
with manageable rewriting of their applications.

RAJA provides various C++ abstractions for parallel loop execution. It
supports: various parallel programming model back-ends, such as OpenMP 
(CPU multithreading and target offload), CUDA, Intel Threading Building Blocks,
etc.; loop iteration space and data view constructs to reorder, 
aggregate, tile, and partition loop iterations; complex loop kernel 
transformations for optimization, such as reordering loop nests, fusing 
loops, etc. RAJA also supports portable atomic operations, parallel scans, 
and CPU and GPU shared memory. After loops have been converted to RAJA, 
developers can explore implementation alternatives via RAJA features without 
altering loop kernels at the application level.

CHAI provides C++ ``managed array'' abstractions that automatically copy 
data to execution memory spaces as needed at run time based on RAJA execution 
contexts. Access to array data in loop kernels looks the same as when using
traditional C-style arrays.

Umpire provides a portable API for managing complex memory resources by 
providing uniform access to other libraries and utilities that provide
system-specific capabilities. Umpire decouples resource allocation from 
specific memory spaces, allocators, and operations. The memory introspection 
functionality of Umpire enables applications and libraries to make memory 
usage decisions based on allocation properties (size, location, sharing 
between packages, etc.)

All three software libraries are open source and available on
GitHub~\cite{RAJA-github, CHAI-github, Umpire-github}. There they provide
regular software and documentation releases. Each project has dedicated email
lists, issue tracking, test suites, and automated testing.

\paragraph{Recent Progress}

In FY18, CHAI and Umpire have been released as open source software projects
and they are now developed on GitHub Recent development has focused on 
user documentation and cleaner integration of these two libraries to give 
applications more flexible and easy access to their capabilities.

Many new features have been added to RAJA in FY18 to enable flexible
loop transformations for complex loop kernels via execution policies.
LLNL applications are assessing this new functionality now in a 
"pre-release" version; it will be generally available before the end of FY18.

The RAJA Performance Suite~\cite{RAJAPerf-github} was released and made 
available on Github in January 2018. The Suite is used to assess and track 
performance of RAJA across programming models and diverse loop 
kernels. It is also being used for compiler acceptance testing in the CORAL 
procurement and was prepared for use as a benchmark for the CORAL-2 procurement.

In 2018, the RAJA project expanded its visibility beyond DOE NNSA Labs. 
Recent presentations include a RAJA tutorial at the 2018 ECP Annual Meeting 
and an application use case study the 2018 NVIDIA GPU Tech Conference (GTC). 
Future tutorials are planned at 2018 ATPESC and GTC 2019. Also, a RAJA paper 
and $1/2$-day tutorial proposal were submitted to SC18.

\paragraph{Next Steps}

Our next efforts include:
\begin{enumerate}
\item {\bf Fill RAJA Gaps:} Not all features are available for all programming
  model back-ends; as models mature, such as OpenMP4.5, these gaps will be
    filled.
\item {\bf Expand RAJA User Guide and Tutorial:} Build example codes and user
  documentation for latest RAJA features and prepare for future tutorials
    (ATPESC 2018 and SC18).
\item {\bf Expand RAJA Performance Suite:} Include kernels that exercise more
  application use cases and RAJA features.
\item {\bf Focus RAJA Vendor Interaction:} Work with CORAL vendors to address
  issues as applications port to the Sierra platform at LLNL; establish early
    interactions with CORAL-2 vendors to ensure RAJA will be supported well on
    CORAL-2 systems.
\item {\bf Expand Umpire Capabilities:} Explore potential collaboration with
  relevant ECP efforts, such as SICM project.
\end{enumerate}
\subsubsection{\stid{1.18} Kokkos} 

\paragraph{Overview} 

The Kokkos C++ Performance Portability Ecosystem is a production-level solution for writing modern C++ applications in an hardware-agnostic way.
Started by Sandia National Laboratories, it is now supported by developers at the Argonne, Berkeley, Oak Ridge, Los Alamos and Sandia National Laboratories as well as the Swiss National Supercomputing (Centre).
It is now used by more than a hundred HPC projects, and Kokkos-based codes are running regularly at-scale on half of the top ten supercomputers in the world. 
The EcoSystem consists of multiple libraries addressing the primary concerns for developing and maintaining applications in a portable way.
The three main components are the Kokkos Core Programming Model, the Kokkos Kernels Math Libraries and the Kokkos Tools.
Additionally, the Kokkos team is participating in the ISO C++ standard development process, to get successful concepts from the Kokkos EcoSystem incorporated into the standard. 
Its development is largely funded as part of the Exascale Computing Project, with a mix of NNSA ATDM and Office of Science sources. 

 
\paragraph{Key Challenges}

One of the biggest challenges for the ExaScale supercomputing era is the proliferation of different computer architectures, and their associated mechanisms to program them.
Vendors have an incentive to develop their own models in order to have maximum freedom of exposing special hardware capabilities, and potentially achieve "vendor-lock-in".
This poses the problem for applications that they may need to write different variants of their code for different machines - an effort which can be simply not feasible for many of the larger application and library projects.

The Kokkos project aims at solving this issue by providing a programming solution which provides a common interface build upon the vendor specific software stacks.
There are a number of technical challenges associated with that. 
First an abstraction must be designed which is restricted enough to allow mapping to a wide range of architectures while allowing exploitation of all the hardware capabilities provided by new architectures. 
Secondly, the development of support for a new architecture may take significant resources. In order to provide a timely solution for applications in line with the availability of the machine, CoDesign collaborations with the vendors are critical.
At the same time software robustness, quality and interface stability is of utmost importance. 
In contrast to libraries such as the BLAS, programming models permeate the entire code base of an application, and are not isolated to simple call sites. 
API changes thus would require a lot of work inside of the users code base. 
A fourth challenge is that in order to debug and optimize the code base tools are required to gain insights into the application. 

Besides the technical challenges, 
a comprehensive support and training infrastructure is absolutely critical for a new programming model to be successful.
Prospective users must learn how to use the programming model, current users must be able to bring up issues with the development team and access detailed documentation, and the development team of the model must be able to continue technical efforts without being completely saturated with support tasks. 
The latter point became a significant concern for the Kokkos team with the expected growth of the user base through ECP.  
Already before the launch of ECP, there were multiple application or library teams starting to use Kokkos for each developer on the core team -- a level not sustainable into the future without a more scalable support infrastructure. 
This issue was compounded by the fact that Kokkos development was funded through NNSA projects, making it hard to justify extensive support for open science applications. 

\paragraph{Solution Strategy}

To address the challenges the Kokkos team is developing a set of libraries and tools which allow application developers to implement, optimize and maintain performance portable codes. 
At its heart the EcoSystem provides the Kokkos Core Programming Model.
Kokkos Core is a programming model for parallel algorithms that use many-core chips and share memory among those cores.
The programming model includes abstractions for frequently used parallel execution patterns, policies that provide details for how those patterns are executed, and execution spaces that denote on which execution agents the parallel computation is performed. 
Kokkos Core also provides fundamental data structures with policies that provide details for how those data structures are laid out in memory, memory spaces that denote in which memory the data reside, and data access traits conveying special data access semantics.
The model works by requiring that application development teams implement their algorithms in terms of Kokkos’ patterns, policies, and spaces. 
Kokkos Core can then map these algorithms onto the target architecture according to architecture-specific rules necessary to achieve best performance.

Kokkos Kernels is a software library of linear algebra and graph algorithms used across many HPC applications to achieve best (not just good) performance on every architecture. The baseline version of this library is written using the Kokkos Core programming model for portability and good performance. The library has architecture-specific optimizations or uses vendor-specific versions of these mathematical algorithms where needed. This reduces the amount of architecture-specific software that an application team potentially needs to develop, thus further reducing their modification cost to achieve “best in class” performance. 

Kokkos Tools is an innovative “plug in” software interface and a growing set of performance measurement and debugging tools that plug into that interface for application development teams to analyze the execution and memory performance of their software. Teams use this performance profiling and debugging information to determine how well they have designed and implemented their algorithms and to identify portions of their software that should be improved. Kokkos Tools interfaces  leverage the Kokkos Core programming model interface to improve an application developer’s experience dramatically, by forwarding application specific information and their context within the Kokkos Core programming model to the tools.

Kokkos Support addresses the challenges of establishing, growing and maintaining the user community.
First and foremost, it provides explicit means for supporting all DOE ECP applications. 
A main component of that is funding for local Kokkos experts at the Sandia, Oak Ridge, Argonne, Berkeley and Los Alamos laboratories which can serve as direct contacts for local applications and the users of the leadership computing facilities. 
Secondly, the project develops and maintains a reusable support infrastructure, which makes supporting more users scalable and cost effective. 

The support infrastructure consists of GitHub wiki pages for the programming guide and API reference, GitHub issues to track feature requests and bug reports, a Slack channel for direct user-to-user and user-to-developer communication, and tutorial presentations and cloud-based Kokkos hands-on exercises. 

The Kokkos Team is also actively engaging the ISO C++ Committee, where it provides about a third of the members interested in HPC.
This strong engagement enables the team to lead or contribute to numerous proposals.
Among those proposals the team leads are abstractions for multi dimensional arrays based on Kokkos View, atomic operations on generic types and linear algebra algorithms based on Kokkos Kernels, which cover not only the classic Fortran BLAS capabilities, but also batched BLAS and mixed precision linear algebra.
The team also has a central role in the primary proposal introducing heterogeneous computing into the C++ standard via the executors concept.

\paragraph{Recent Progress}

The Kokkos project now consists of an integrated developers team spanning five DOE National Laboratories.
In particular both NNSA and Office of Science funded developers are working based off the same task and code management system, use a shared slack channel, and attend a common weekly team meeting.
This ensures that no duplication of effort happens, and makes Kokkos a true inter laboratory project.

Kokkos is now used by many applications in production across the entire spectrum of DOE's super computers.
Support for current production platforms is mature and stable.
Work on supporting the upcoming ExaScale platforms has begun and initial capabilities for AMD GPUs and Intels GPUs are working.
On the AMD side this is despite the fact that full support was previously available, but had to be removed due to the deprecation of the underlying programming model by AMD.

Three Kokkos specific multi-day boot camps were organized with a total attendance on the order of 60 developers.
Additionally the team provided single day tutorials at numerous venues with several hundred attendees in aggregate.
The slack channel now sees daily questions from numerous users, and has attracted even vendor representatives who help answer machine specific questions.
The team finished developing a full API documentation as well as adding use case descriptions for common patterns found in applications.

At the C++ committee, the MDSpan proposal is now in wording review - meaning that the technical design is approved. 
MDSpan will be able to provide all the core capabilities of Kokkos\:\:View.
This includes compile and runtime extents, customizable layouts, and data access traits.
The extension to heterogeneous memory can be achieved by trivial extensions. 
Furthermore, the atomic\_ref proposal was voted into C++20.
This capability will provide atomic operations on generic allocations as powerful as Kokkos' atomic operations.
In particular it allows atomic operations on types independent of their size, and not just the ones native in the hardware.
A very recent development, is the proposal for linear algebra functions.
It entails functionality covering all of BLAS 1, 2, and 3, but extends it to any scalar types (including mixing of scalar types) and batched operations.
The proposal was approved by the relevant study groups, as well as the library evolution incubator group.
The Kokkos team was also able to gain co-authors from NVIDIA, Intel and AMD - providing significant support from the leading hardware vendors.

\paragraph{Next Steps}

The most pressing next task is to complete and then mature support for the upcoming ExaScale architectures.
Most of Kokkos's functionality is expected to be available by the end of FY20 for those systems, which will provide another year of time to mature the support before the first platforms will be delivered.

On the programming model evolution side, more explicit asynchronous capabilities including the creation of graphs of kernel launches is a high priority.

At the plumbing level, the team will start to replace some of the implementation level of Kokkos by the ISO C++ capabilities such as atomic\_ref and mdspan.

For Kokkos tools an upcoming capability will be the addition of autotuning tools. This will help with the increasingly difficult task of coming up with heuristics to determine good runtime settings for kernels on all the different architectures.

And last but not least, the team will work on getting the proposed new ISO C++ capabilities into the C++23 draft standard, so that they will be available to our users as a vendor provided capability during the lifetime of the first ExaScale platforms.
