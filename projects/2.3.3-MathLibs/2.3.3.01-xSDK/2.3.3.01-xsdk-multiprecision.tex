\subsubsection{\stid {3.01} xSDK Sub-project: multiprecision} 
\paragraph{Overview} 
Within the past years, hardware vendors have started designing low precision special function units 
in response to the demand of the Machine Learning community for high compute power
in low precision formats. At the same time, the gap between compute power
on the one hand and memory bandwidth on the other hand keeps increasing, 
making data access and communication prohibitively expensive compared to arithmetic operations.
Having the choice between ignoring the hardware trends and continuing the traditional path
or adjusting the software stack to the changing hardware designs, the US Exascale Computing Project
decided to build a multiprecision focus effort to take on the challenge of designing and engineering novel algorithms capable to exploit the compute power available in low precision and to adjust the communication format to application specific needs.
As part of the xSDK project, the multiprecision focus effort is a coordinated effort creating synergies via cross-institutional collaboration.

\paragraph{Key Challenges}
Generally, there exists a strong relationship between the precision used in arithmetic operations and the accuracy of the computed result. Since scientific applications need to provide high quality output, replacing high precision formats with low precision formats throughout a complete application code is generally not feasible. Instead, to utilize lower precision formats, the underlying numerical algorithms have to be redesigned to employ low precision formats for the most time-consuming parts while preserving  high accuracy in the solution. In this context, the arithmetic operations are only one aspect. As the execution time of many scientific applications is dominated by communication and memory access, the algorithm redesign also has to include strategies for compressing data to reduce the pressure on the memory bandwidth. This aspect becomes even more relevant as the arithmetic power continues to grow faster than the memory bandwidth, therewith widening the gap between arithmetic performance and memory performance, see Figure~\ref{fig:xsdk-machinebalance}.

\begin{figure}[htb]
	\centering
	\includegraphics[width=.8\columnwidth]{projects/2.3.3-MathLibs/2.3.3.01-xSDK/xSDK-machinebalance.pdf}
	%\includegraphics[width=.8\columnwidth]{xSDK-machinebalance.pdf}
	\caption{\label{fig:xsdk-machinebalance} Evolution of the machine balance of processors over different hardware generations.}
\end{figure}


\paragraph{Solution Strategy}
In the multiprecision effort, the team assesses current status and functionalities, advances the theoretical knowledge on multiprecision algorithms, designs prototype implementations and multiprecision interoperability layers, deploys production-ready multiprecision algorithms in the xSDK math libraries, ensures multiprecision cross-library interoperability and integrates multiprecision algorithms into ECP application projects. The long list of project activities is organized in a multi-phase approach:
The first stage is dedicated to the exploration of the design space and existing research efforts focusing on low precision, mixed precision, and extended precision. To this end, the effort  includes internationally-renown external experts for mixed precision algorithms. In the second stage, the multiprecision effort increasingly focuses on developing production code ready to be used in the ECP application projects. Relevant algorithmic functionality includes sparse linear algebra, multigrid methods, preconditioners, iterative solvers, low-rank approximations, and mixed precision machine learning.
On the hardware side, special focus is put on low-precision special function units like NVIDIAâ€™s tensor cores that -- originally designed for machine learning algorithms -- offer about an order of magnitude higher arithmetic performance than conventional fp64 units. 
In the third phase of the multiprecision effort, the project team will aid the ECP application projects with the adoption of multiprecision functionality and continue to adapt to new hardware technologies.


\paragraph{Recent Progress}
As a first step, the multiprecision team surveyed the state of the art in terms of mixed precision algorithms, low precision and extended precision algorithms, and the algorithmic needs of the ECP application projects. The results of this landscape assessment are made publicly available as ``A Survey of Numerical Methods Utilizing Mixed Precision Arithmetic''~\cite{Anztetal2020}.
A more compact version of this survey -- exclusively focusing on numerical linear algebra -- has been submitted as a journal article.

Based on the findings of the multiprecision landscape assessment, we created a set of cross-institutional focus groups that address different algorithms and aspects of the ECP software ecosystem including dense and sparse direct solvers, eigensolvers, Krylov-based iterative solvers, multigrid methods, preconditioners, Fast Fourier Transform, and machine learning technology. Orthogonal to those, we created focus groups on the design on a memory accessor that separates the arithmetic precision from the communication precision, and the efficient realization of multiprecision basic building blocks like sparse matrix vector multiply.
In bi-weekly virtual meetings, the progress on the different efforts is presented and discussed as many of these efforts are closely related. As another integral part of the bi-weekly phone calls we established a series of short talks where each meeting is commenced by an invited talk presenting an idea, success story, or progress update on mixed precision functionality to the audience. 

Following the idea of decoupling the memory precision from the arithmetic precision to reduce the pressure on the memory bandwidth, the team released an accessor design document detailing the implementation and usage of a memory accessor that compresses data, e.g. by converting to a lower precision format, before invoking memory operations.
The document has been made available to the ECP community.

\paragraph{Next Steps}

Our next efforts include 
\begin{itemize}
    \item the publication of a compacted version of the multiprecision landscape assessement as a scientific journal paper,
    \item the deployment of the accessor separating memory precision and arithmetic precision in the Ginkgo library with support for AMD GPUs, NVIDIA GPUs, and multicore CPUs,  
    \item the implementation of compressed basis Krylov solvers that utilize the memory accessor to compact the Krylov search directions,
    \item the advancement of multiprecision capabilities for solvers, preconditioners, and other ECP-relevant kernels in xSDK libraries, including
    \subitem - the design and implementation of mixed precision eigensolvers,
    \subitem - the research and realization of mixed precision multigrid solvers,
    \subitem - the design and implementation of mixed precision sparse factorizations.
\end{itemize}

